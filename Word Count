Nandini Rajeswaran

Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /__ / .__/\_,_/_/ /_/\_\   version 2.2.0
      /_/

Using Python version 2.6.9 (unknown, Feb  7 2017 00:08:08)
SparkSession available as 'spark'.
>>> sc = spark.sparkContext
>>> data = sc.textFile("file:///Users/nandinirajeswaran/Applications/spark-2.2.0-bin-hadoop2.7/Bonus")
>>> rdd = data.flatMap(lambda x:[(c,1) for c in x])
>>> rdd1 = rdd.reduceByKey(lambda x,y : x+y)
>>> rdd1.collect()
[(u'A', 79), (u'C', 123), (u'G', 105), (u'T', 61)]
